{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_1ai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "$m$ is the Exponentially-Weighted Moving Average (EWMA), of minibatch gradient. So $m$ will evolve more slowly then gradient, has lower volatility than gradient. Minibatch gradient has high variance, because gradient is averaged across small number of samples (standard error for gradient is $O\\left(\\frac{1}{\\sqrt{N}}\\right)$. This can be especially problematic when we traverse across sufraces like gently sloping valleys. This causes gradient to oscillate (left picture below). But if we use EWMA, we can have a smoother gradient descent (right picture).\n",
    "\n",
    "![title](https://amva4newphysics.files.wordpress.com/2017/04/longnarrowvalley.png)\n",
    "\n",
    "[Credit](https://amva4newphysics.wordpress.com/2017/04/03/understanding-neural-networks-part-iii-diagnosis-and-treatment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_1aii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Because we divide by v, which is rolling avg of magnitudes, we shrink updates where gradient “bounces around” between large positive and negative values, because EWMA average of gradients of such gradients get close to zero. \n",
    "Furthermore, v will become much bigger, since we’re averaging absolute *magnitudes*, shrinking parameter updates even further. So model parameters whose gradients are more constant in sign and magnitude will get larger updates than those whose oscillate between positive and negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_1b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_1bi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "$$\\frac{1}{1-p_{drop}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_1bii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "We apply dropout only during training, because we want to force different subnetworks of our Deep Neural Network to \"learn\" from our data on their own. It is a form of ensembling, so that at test and eval time, we can effectively ensemble across different subnetworks' learned models, to increase DNN accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2ai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2aii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: \n",
    "![title](imgs/a3_problem2a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "$2*n$ steps, or $O\\left(N\\right)$, because each word will require a SHIFT, and an (RIGHT/LEFT)-ARC step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to parser_transitions.py](parser_transitions.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2di.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "[Link to parser_transitions.py](parser_transitions.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2dii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2diii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "[Link to parser_model.py](parser_model.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Error type: **Verb Phrase Attachment Error**\n",
    "\n",
    "Incorrect dependency: wedding -> fearing\n",
    "\n",
    "Correct dependency: heading -> fearing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Error type: **Coordination Attachment Error**\n",
    "\n",
    "Incorrect dependency: makes -> rescue\n",
    "\n",
    "Correct dependency: rush -> rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fiii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Error type: **Prepositional Phrase Attachment Error**\n",
    "\n",
    "Incorrect dependency: named -> Midland\n",
    "\n",
    "Correct dependency: Joe O’Neill -> Midland\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a3_2fiv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "Error type: **Modifier Attachment Error**\n",
    "\n",
    "Incorrect dependency: elements -> most\n",
    "\n",
    "Correct dependency: crucial -> most"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
