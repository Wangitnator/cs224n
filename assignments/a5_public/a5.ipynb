{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1_intro_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1_intro_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers:\n",
    "We use embeddings to represent sparse data (words), in lower-dimensional space.\n",
    "\n",
    "There are between O(10^5) and O(10^6) words in the English language, but only O(10^2) characters, so we would expect:\n",
    "\n",
    "1) character frequenc matrices to **not** be sparse\n",
    "\n",
    "2) embeddings to be of significantly lower dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "A) Number of embedding parameters per word, in character embedding model: \n",
    "$$ \\begin{aligned} \n",
    "N_{char} &= |e_{char}| \\times |V_{char}| + \\left(f \\times e_{char} \\times k \\right) + 2 \\times \\left( e_char \\times e_char \\right) \\\\\n",
    "N_{char} &= |e_{char}| \\times |V_{char}| + \\left(e_{word} \\times e_{char} \\times k \\right) + 2 \\times \\left( e_char \\times e_char \\right) \\\\\n",
    "N_{char} &\\approx 50 \\times 96 + \\left(256 \\times 50 \\times 5\\right) + 2 \\times \\left(256^2\\right) \\\\\n",
    "N_{char} &\\approx 2 \\times 10^5 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "N_{word} &= \\left|e_{word}\\right| \\times \\left|V_{word}\\right| \\\\\n",
    "N_{word} &= 256 \\times 50000 \\\\\n",
    "N_{word} &= 1.28 \\times 10^7 \\\\\n",
    "\\implies \\frac{N_{word}}{N_{char}} &\\approx 64 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So word embedding model has ~60x more parameters than a character-embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "With an RNN-based character-embedding model, the earlier characters in a word have less weighting on final word vector, than later characters, due to chaining of RNN-hidden units. Whereas in sentences, word proximity within a sentence correlates with word relatedness, so RNN's seem like a natural choice. However within words, actually earlier characters should be no less important than later characters in a word, for determining semantic meaning of a word (e.g. \"unlucky\", n.b. prefix \"un\"). But CNN's, by definition apply the same operation(convolution) on across input data series, so they seem like a naturally better choice for character-level NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "Max-Pooling is better for detecting contrasts, or edges in Computer Vision.\n",
    "\n",
    "Average-Pooling is more sensitive to data in all input cells, whereas Max-Pooling only sensitive to max-valued input cell. It's disadvantage is that if cells are very-high and very-low, the average may end up close to zero, hiding the variation in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1ei.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1eii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](vocab.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](utils.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](vocab.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1h.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](highway.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1i.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](cnn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](model_embeddings.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1k.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](nmt_model.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem1l.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2_intro_i.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2_intro_ii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](char_decoder.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](char_decoder.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](char_decoder.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code](char_decoder.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2fi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem2fii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: my BLEU score was ~24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem3a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers:\n",
    "1) Present in vocab.json:\n",
    "* _traducir_\n",
    "* _traduce_\n",
    "\n",
    "2) Not present in vocab.json:\n",
    "* _traduzco_\n",
    "* _traduces_\n",
    "* _traduzca_\n",
    "* _traduzcas_\n",
    "\n",
    "3) Explanation:\n",
    "* If verb forms aren’t in training data corpus, then word-based NMT model won’t recognize these words, won’t be able to translate. \n",
    "* Character-based NMT models could help here, by estimating word’s meaning-encoding, through composition of character-level encodings. \n",
    "* So when new word appears in test data, but never in training data, character-based NMT could estimate word’s meaning using it’s characters of which it’s composed, and it’s character-level embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem3bi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers:\n",
    "Word2Vec Word-Embeddings:\n",
    "* financial: economic (0.462)\n",
    "* neuron: nerve (0.559) \n",
    "* Francisco: san (0.184)\n",
    "* naturally: occurring (0.545)\n",
    "* expectation: norms(0.627)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem3bii-part1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem3bii-part2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers:\n",
    "Part II: Character-based Embeddings:\n",
    "* financial: vertical (0.301) \n",
    "* neuron: Newton (0.354)\n",
    "* Francisco: France (0.420)\n",
    "* naturally: practically (0.302)\n",
    "* expectation: exception (0.389)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### financial:\n",
    "![financial](imgs/word_financial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neuron:\n",
    "![neuron](imgs/word_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Francisco:\n",
    "![Francisco](imgs/word_Francisco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naturally:\n",
    "![naturally](imgs/word_naturally.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expectation:\n",
    "![expectation](imgs/word_expectation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem3biii.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### financial:\n",
    "![financial](imgs/char_financial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neuron:\n",
    "![neuron](imgs/char_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Francisco:\n",
    "![Francisco](imgs/char_Francisco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naturally:\n",
    "![naturally](imgs/char_naturally.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expectation:\n",
    "![expectation](imgs/char_expectation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/a5_problem3c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "1) Spanish:\n",
    "* Bien, al da siguiente estbamos en Cleveland.\n",
    "* La epifana es que la muerte es parte de la vida.\n",
    "\n",
    "2)\tEnglish\n",
    "* Well, the next day we were in Cleveland.\n",
    "* The epiphany is  that death is a part of life.\n",
    "\n",
    "3) A4 Translation:\n",
    "* Well, the next day we were in &lt;unk&gt;\n",
    "* &lt;unk&gt; is that death is part of life.\n",
    "\n",
    "4) Char-CNN Translation:\n",
    "* Well, the next day we were in Christmas.  \n",
    "* The evidence is that death is part of life.\n",
    "\n",
    "5)\tEvaluation:\n",
    "* Example a: incorrect, perhaps because \"Cleveland\" is a proper name (although the suffix \"land\" could have provided a hint that word referred to proper place).\n",
    "* Example b: largely correct, because \"evidence\" and \"epiphany\" have semantically-related (if not similar) meanings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
